{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2866ca-fce2-4a35-b8a6-0695d13ffd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import r5py as r5\n",
    "import pyrosm as pr\n",
    "import geopandas as gpd\n",
    "import geohexgrid as ghg\n",
    "from loguru import logger\n",
    "\n",
    "gpd.options.io_engine = \"pyogrio\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be87976-5aa5-48cc-897e-5b2bb12ed38a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424a17d-6905-4c4a-8454-798aaaaf36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pl.Path(\"../data\") \n",
    "WGS84 = \"epsg:4326\"\n",
    "NZTM = \"epsg:2193\"\n",
    "\n",
    "%ls {DATA_DIR}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dcd11-4cc6-4fe2-90cb-9545362daf9b",
   "metadata": {},
   "source": [
    "# Write an isochrone function using r5py\n",
    "\n",
    "To help address [this Github issue](https://github.com/r5py/r5py/issues/311) .\n",
    "Actually, write two such functions, one based on a user-specified set of grid cells and\n",
    "one based on the [concave hull isochrones of r5r](https://github.com/ipeaGIT/r5r/blob/master/r-package/R/isochrone.R).\n",
    "\n",
    "I find the grid-style function more useful for my work (which often involves gridding up a study area for sampling),\n",
    "because (1) i can set the resolution of my isochrones (via the grid), \n",
    "and (2) i needn't iterate to find a perfect convex hull ratio to use for accurate-looking results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88cdc2-2a08-4eac-aa1b-71962441bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isochrone_g(\n",
    "    transport_network: r5.TransportNetwork,\n",
    "    transport_modes: list[r5.TransportMode],\n",
    "    origins: gpd.GeoDataFrame,\n",
    "    time_bounds: list[float],\n",
    "    grid: gpd.GeoDataFrame,\n",
    "    destinations: gpd.GeoDataFrame | None = None,\n",
    "    departure: dt.datetime | None = None,\n",
    "    snap_to_network: bool | int = False,\n",
    "    **kwargs: dict,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Compute grid-style isochrones from the given origin points.\n",
    "\n",
    "    More specifically, given a GeoDataFrame of WGS84 origin points with a unique\n",
    "    identifier column 'id' and a grid of WGS84 polygons with unique identifier column\n",
    "    'id', whose polygons ideally cover the study area without overlaps \n",
    "    and are clipped to coastlines, do the following.\n",
    "    Choose one representative point from each grid cell to form a set of destination points.\n",
    "    Alternatively, use ``destinations``, if given, which should also have an 'id' column\n",
    "    that matches the grid cell IDs.\n",
    "    For each origin and for each duration t (minutes) in the given list of time bounds,\n",
    "    find all destinations that are at most t minutes away when departing from the\n",
    "    origin at the given departure time (which defaults to the current datetime),\n",
    "    using the given transport modes, and travelling through the given transport nework.\n",
    "    Collect all grid cells containing those reachable destinations, dissolve them,\n",
    "    and set that as the isochrone for that origin and duration.\n",
    "    Return a GeoDataFrame with the following columns.\n",
    "\n",
    "    - ``'from_id'``: origin point ID\n",
    "    - ``'travel_time_percentile'``: string; defaluts to 'p50' if no percentiles are given\n",
    "    - ``'time_bound'``: float; one of the given time bounds\n",
    "    - ``'geometry'``: (Multi)Polygon isochrone.\n",
    "\n",
    "    You can customise the isochrone calculation as follows.\n",
    "\n",
    "    - Snap the origin points to the street network before routing if and only if\n",
    "      ``snap_to_network``\n",
    "      If ``True``, then the default search radius\n",
    "      defined in com.conveyal.r5.streets.StreetLayer.LINK_RADIUS_METERS is used;\n",
    "      if int, then use that many meters as the search radius for snapping.\n",
    "    - Pass in any keyword arguments accepted by :class:`r5py.RegionalTask`,\n",
    "      e.g. `departure_time_window`, `percentiles`, `max_time_walking`.\n",
    "\n",
    "    NOTES:\n",
    "\n",
    "    - All given GeoDataFrame will be converted to coordinate reference system (CRS) WGS84 before routing, \n",
    "      then converted back to the CRS of the grid.\n",
    "    - Uses r5py to do the routing.\n",
    "\n",
    "    \"\"\"\n",
    "    # Prepare inputs\n",
    "    logger.info(\"Prepare inputs\")\n",
    "    time_bounds = sorted(set(time_bounds))\n",
    "    origins = origins.to_crs(WGS84)\n",
    "    final_crs = grid.crs\n",
    "    grid = grid.to_crs(WGS84)\n",
    "    if destinations is None:\n",
    "        destinations = grid.assign(geometry=lambda x: x.representative_point())\n",
    "    else:\n",
    "        destinations = destinations.to_crs(WGS84)\n",
    "\n",
    "    # Compute travel times\n",
    "    logger.info(\"Compute travel times\")\n",
    "    ttm = r5.TravelTimeMatrixComputer(\n",
    "        transport_network,\n",
    "        origins=origins,\n",
    "        destinations=destinations,\n",
    "        departure=departure,\n",
    "        transport_modes=transport_modes,\n",
    "        snap_to_network=snap_to_network,\n",
    "        **kwargs,\n",
    "    )\n",
    "    f = (\n",
    "        ttm.compute_travel_times()\n",
    "        .dropna()\n",
    "        .rename(columns={\"travel_time\": \"travel_time_p50\"})\n",
    "        # Melt in case of multiple travel time percentiles\n",
    "        .melt(id_vars=[\"from_id\", \"to_id\"], var_name=\"pctile\", value_name=\"travel_time\")\n",
    "        .assign(pctile=lambda x: x[\"pctile\"].str.split(\"_\").str[-1])\n",
    "    )\n",
    "    if f.empty:\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "    # Build isochrones from the grid cells of the reachable points\n",
    "    logger.info(\"Build isochrones\")\n",
    "    records = []\n",
    "    for (from_id, pctile), group in f.groupby([\"from_id\", \"pctile\"]):\n",
    "        for time_bound in time_bounds:\n",
    "            iso = grid.merge(\n",
    "                group.loc[lambda x: x[\"travel_time\"] <= time_bound].rename(\n",
    "                    columns={\"to_id\": \"id\"}\n",
    "                )\n",
    "            ).dissolve()\n",
    "            records.append(\n",
    "                {\n",
    "                    \"from_id\": from_id,\n",
    "                    \"travel_time_percentile\": pctile,\n",
    "                    \"time_bound\": time_bound,\n",
    "                    \"geometry\": iso[\"geometry\"].iat[0] if not iso.empty else np.nan,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return gpd.GeoDataFrame(pd.DataFrame.from_records(records), crs=WGS84).to_crs(final_crs)\n",
    "\n",
    "def get_osm_nodes(transport_network: r5.TransportNetwork) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Return the OSM nodes underlying the given transport network.\n",
    "    Include in the GeoDataFrame an ID column 'id' that is simply the index of the \n",
    "    GeoDataFrame.\n",
    "    \"\"\"\n",
    "    import com.conveyal.r5\n",
    "    \n",
    "    k = com.conveyal.r5.streets.VertexStore.FIXED_FACTOR\n",
    "    v = transport_network._transport_network.streetLayer.vertexStore\n",
    "    lonlats = zip(list(v.fixedLons.toArray()), list(v.fixedLats.toArray()))\n",
    "    nodes = gpd.GeoDataFrame(\n",
    "        geometry=[shapely.Point(lon / k, lat / k) for lon, lat in lonlats],\n",
    "        crs=\"epsg:4326\",\n",
    "    )\n",
    "    nodes[\"id\"] = nodes.index\n",
    "    return nodes\n",
    "\n",
    "def isochrone_ch(\n",
    "    transport_network: r5.TransportNetwork,\n",
    "    transport_modes: list[r5.TransportMode],\n",
    "    origins: gpd.GeoDataFrame,\n",
    "    time_bounds: list[float],\n",
    "    destinations: gpd.GeoDataFrame | None = None,\n",
    "    departure: dt.datetime|None=None,\n",
    "    snap_to_network: bool|int=False,\n",
    "    sample_frac: float=0.8,\n",
    "    concave_hull_ratio=0.15,\n",
    "    **kwargs: dict,\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Compute concave-hull-style isochrones from the given origin points.\n",
    "\n",
    "    More specifically, given a GeoDataFrame of WGS84 origin points with a unique\n",
    "    identifier column 'id' do the following.\n",
    "    Choose a set of destination points by sampling ``sample_frac`` of all OSM nodes in\n",
    "    the underlying network.\n",
    "    Alternatively, use ``destinations``, if given, which should also have an 'id' column\n",
    "    that matches the grid. \n",
    "    For each origin and for each duration t (minutes) in the given list of time bounds,\n",
    "    find all destinations that are at most t minutes away when departing from the\n",
    "    origin at the given departure time (which defaults to the current datetime),\n",
    "    using the given transport modes, and travelling through the given transport nework.\n",
    "    Collect all such destinations, compute their concave hull using the given\n",
    "    concave hull ratio, and set that as the isochrone for that origin and duration.\n",
    "    Return a GeoDataFrame with the following columns.\n",
    "\n",
    "    - ``'from_id'``: origin point ID\n",
    "    - ``'travel_time_percentile'``: string; defaluts to 'p50' if no percentiles are given\n",
    "    - ``'time_bound'``: float; one of the given time bounds\n",
    "    - ``'geometry'``: (Multi)Polygon isochrone.\n",
    "\n",
    "    You can customise the isochrone calculation as follows.\n",
    "\n",
    "    - Snap the origin points to the street network before routing if and only if\n",
    "      ``snap_to_network``\n",
    "      If ``True``, then the default search radius\n",
    "      defined in com.conveyal.r5.streets.StreetLayer.LINK_RADIUS_METERS is used;\n",
    "      if int, then use that many meters as the search radius for snapping.\n",
    "    - Pass in any keyword arguments accepted by :class:`r5py.RegionalTask`,\n",
    "      e.g. `departure_time_window`, `percentiles`, `max_time_walking`.\n",
    "\n",
    "    NOTES:\n",
    "\n",
    "    - All given GeoDataFrames will be converted to coordinate reference system (CRS) WGS84 before routing, \n",
    "      then converted back to the CRS of the origin points.\n",
    "    - Uses r5py to do the routing.\n",
    "\n",
    "    \"\"\"\n",
    "    logger.info(\"Prepare inputs\")\n",
    "    final_crs = origins.crs\n",
    "    time_bounds = sorted(set(time_bounds))\n",
    "    osm_nodes = get_osm_nodes(transport_network).sample(frac=sample_frac, random_state=1)\n",
    "\n",
    "    # Compute travel times\n",
    "    logger.info(\"Compute travel times\")\n",
    "    ttm = r5.TravelTimeMatrixComputer(\n",
    "        transport_network,\n",
    "        origins=origins.to_crs(WGS84),\n",
    "        destinations=osm_nodes,\n",
    "        departure=departure,\n",
    "        transport_modes=transport_modes,\n",
    "        snap_to_network=snap_to_network,\n",
    "        **kwargs,\n",
    "    )\n",
    "    f = (\n",
    "        ttm.compute_travel_times()\n",
    "        .dropna()\n",
    "        .rename(columns={\"travel_time\": \"travel_time_p50\"})\n",
    "        # Melt in case of multiple travel time percentiles\n",
    "        .melt(id_vars=[\"from_id\", \"to_id\"], var_name=\"pctile\", value_name=\"travel_time\")\n",
    "        .assign(pctile=lambda x: x[\"pctile\"].str.split(\"_\").str[-1])\n",
    "    )\n",
    "    if f.empty:\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "    # Build isochrones as concave hulls of reachable points\n",
    "    logger.info(\"Build isochrones\")\n",
    "    records = []\n",
    "    for (from_id, pctile), group in f.groupby([\"from_id\", \"pctile\"]):\n",
    "        for time_bound in time_bounds:\n",
    "            reachable_nodes = osm_nodes.merge(\n",
    "                group\n",
    "                .loc[lambda x: x[\"travel_time\"] <= time_bound]\n",
    "                .rename(columns={\"to_id\": \"id\"})\n",
    "            )\n",
    "            iso = shapely.concave_hull(reachable_nodes.unary_union, ratio=concave_hull_ratio)\n",
    "            records.append(\n",
    "                {\n",
    "                    \"from_id\": from_id,\n",
    "                    \"travel_time_percentile\": pctile,\n",
    "                    \"time_bound\": time_bound,\n",
    "                    \"geometry\": iso if not iso.is_empty else np.nan,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    logger.info(\"Build GeoDataFrame\")\n",
    "    return gpd.GeoDataFrame(pd.DataFrame.from_records(records), crs=WGS84).to_crs(final_crs)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184f3ae-9411-450b-8071-1e0f97d81fd3",
   "metadata": {},
   "source": [
    "# Illustrate the functions \n",
    "\n",
    "Use data from my location of Auckland, New Zealand, which i can confidently scrutinise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06719b04-992a-46eb-8bee-4e7648aa2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Auckland OSM and GTFS data\n",
    "%time akl_pbf_path = pr.get_data(\"Auckland\", directory=DATA_DIR)\n",
    "akl_gtfs_path = DATA_DIR / \"auckland_gtfs_20230824.zip\"\n",
    "\n",
    "# Make the R5 transport network from these\n",
    "%time transport_network = r5.TransportNetwork(akl_pbf_path, [akl_gtfs_path])\n",
    "transport_modes = [\n",
    "    r5.TransportMode.TRANSIT,\n",
    "    r5.TransportMode.WALK,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387fc48-0eae-45e0-be94-931f02dcfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Make a hexagon grid of circumradius 100 m covering the transport network\n",
    "# and clipping to coastlines\n",
    "study_area = (\n",
    "    # Contains coastlines\n",
    "    gpd.read_file(DATA_DIR / \"auckland.gpkg\")  \n",
    "    .clip(\n",
    "        gpd.GeoDataFrame(geometry=[transport_network.extent], crs=WGS84)\n",
    "        .to_crs(NZTM)\n",
    "    )\n",
    ")\n",
    "path = DATA_DIR / \"auckland_grid_100m.gpkg\"\n",
    "if not path.exists():\n",
    "    logger.info(\"Making grid\")\n",
    "    grid = ghg.make_grid_from_gdf(study_area, 100, clip=True)\n",
    "    grid.to_file(path, driver=\"GPKG\")\n",
    "else:\n",
    "    grid = gpd.read_file(path)\n",
    "\n",
    "display(grid.head())\n",
    "print(\"#grid cells =\", grid.shape[0])\n",
    "\n",
    "# Plot the study area and the some grid cells.\n",
    "# The entire grid takes too long to plot\n",
    "pd.concat([study_area, grid.iloc[55_000:56_000]]).explore(tiles=\"CartoDB positron\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0fea4-d51f-42c2-ab42-56298ed83c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some origin points, some of which might involve ferry rides\n",
    "\n",
    "origins = gpd.read_file(DATA_DIR / \"auckland_points.geojson\").assign(id=lambda x: x.index).to_crs(NZTM)\n",
    "display(origins)\n",
    "display(origins.assign(geometry=lambda x: x.buffer(50)).explore(tiles=\"CartoDB positron\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aea8bd-8d1c-4ef7-9997-a0cdf3ff5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Takes ~15 seconds on my computer\n",
    "isos = (\n",
    "    isochrone_g(\n",
    "        transport_network=transport_network, \n",
    "        transport_modes=transport_modes,\n",
    "        origins=origins,\n",
    "        departure=dt.datetime(2023, 8, 28, 8, 0, 0),\n",
    "        time_bounds=[45],\n",
    "        grid=grid.rename(columns={\"cell_id\": \"id\"}),\n",
    "        departure_time_window=dt.timedelta(seconds=35*60),\n",
    "        percentiles=[1, 25, 50],\n",
    "    )\n",
    ")\n",
    "\n",
    "display(isos.head())\n",
    "for ptile, group in isos.groupby(\"travel_time_percentile\"):\n",
    "    print(ptile)\n",
    "    display(group.explore(column=\"from_id\", categorical=True, cmap=\"viridis\", tiles=\"CartoDB positron\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f6945-8e62-468e-8f8b-7c1fc70010a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Takes ~77 seconds on my computer\n",
    "isos = (\n",
    "    isochrone_ch(\n",
    "        transport_network=transport_network, \n",
    "        transport_modes=transport_modes,\n",
    "        origins=origins,\n",
    "        departure=dt.datetime(2023, 8, 28, 8, 0, 0),\n",
    "        time_bounds=[45],\n",
    "        departure_time_window=dt.timedelta(seconds=35*60),\n",
    "        percentiles=[1, 25, 50],\n",
    "    )\n",
    ")\n",
    "\n",
    "display(isos.head())\n",
    "for ptile, group in isos.groupby(\"travel_time_percentile\"):\n",
    "    print(ptile)\n",
    "    display(group.explore(column=\"from_id\", categorical=True, cmap=\"viridis\", tiles=\"CartoDB positron\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
